# [퀴즈 1]

(1) 준지도학습이 둘다 쓴다는 건 확실히 정답. **소량의 고품질 레이블 데이터**를 **대량의 레이블 없는 데이터**를 결합함.

(2) 위와 동일. 다만 적은 양의 레이블 데이터만 이용하는 것이 아니라는 점. 대량의 레이블되지 않은 데이터도 필요로 하긴 하지만, 모델 성능 향상에 도움이 되므로 참.

(3) 비지도학습은 외부 레이블은 없음. 데이터 자체에서 군집을 형성하는데 이것이 **감독 신호**를 생성한다고 봐도 되는 것일까?

(4) 준지도학습은 지도학습과 비지도학습의 조합. 따라서 중간 형태로 볼 수 있음.

(5) 지도학습은 우선적으로 **레이블 데이터**를 필요로 하는 것은 사실. 하지만 무조건적으로 고품질 데이터가 필요한가? 라는 의문이 들긴 함. 약간은 비약이 있다는 생각.

따라서 가장 적절하지 않은건 **5**번이 나을 듯.

# [퀴즈 2]

### 퍼셉트론의 한계

정리) 단층 퍼셉트론은 두 그룹을 가장 잘 구분하는 직선을 찾아냄. (임의의 선의 Loss 값으로부터 가장 좋은 선을 찾아냄.)

따라서 선을 그어 구분하면 XOR 문제를 해결할 수 없으므로 입출력 이외에 한 층이 더 있는 **다층 퍼셉트론**을 이용 해야 함.

...

### 선을 그으면 왜 XOR 문제를 해결할 수 없는가?

XOR은 OR, AND, NAND와 달리 1개의 직선이 아닌, 2개의 직선이나 곡선을 필요로 함.

- OR, AND, NAND의 논리표를 그려서 이를 그래프에 표현해보면 선 하나로 구분이 가능하지만, XOR은 곡선으로 구분할 수밖에 없음.

* **다층 퍼셉트론**은 단층 퍼셉트론에서 은닉층이 추가됨. NAND, OR, AND를 조합하여 XOR을 구현해내서 이용함. 따라서 선이 2개로 구분이 가능해짐.

# [퀴즈 3]

### 퍼셉트론 구현

퍼셉트론 구현부는 이미 코드가 주어져 있다. 이 코드로 알아낼 수 있는게 뭐가 있을까?

`ans1`과 `ans2`로 입력한 값들이 그룹화되어 하나의 직선으로 구분할 수 있음을 보여줌.

```py
def Perceptron(x, w, b):
    y = np.sum(w * x) + b
    if y <= 0:
        ans1 = 4
        return ans1
    else:
        ans2 = 9
        return ans2
```

y값(오차)이 양수냐 음수냐에 따라 가까운 값으로 구분짓는 듯.

# [수업 들으면서 정리한 내용]

인공지능: 인간 지능과 관련된 **인지** 문제를 다루는 분야

- AI/ML/DL (포함 관계)
  - ML: 데이터로부터 특징을 학습하는 알고리즘
  - DL: 신경망을 기반으로 특징을 학습하는 알고리즘

AI면서 ML은 아닌 케이스: Rule-Based System

ML이면서 DL은 아닌 케이스: KNN

### 모델이 데이터을 어떻게 학습하는가?

---

- 지도학습: 입력 데이터와 그에 대응하는 정답(라벨)이 함께 제공되는 학습 방법
- 비지도학습: 정답 라벨이 없는 데이터를 사용함. 데이터와 데이터 간의 유사성을 통해 군집을 찾아내는 방식으로 돌아감.
  - 데이터에 대한 더 깊은 통찰, 이후에 사용할 특징을 추출함.
- 준지도학습: 소량의 고품질 레이블 데이터 → 대량의 레이블 없는 데이터를 결합하여 학습함.
- 자가지도학습: 레이블 없는 데이터 → 자동으로 지도 신호를 생성하여 학습 (인터넷이 활성화되며 데이터가 많아져서 가능함)
  - LLM 모델: 문장 일부를 가리고, 단어를 예측하는 방식으로 학습함.

### DL component

---

1. DATA

Classification, Segmentation, Object Detection(좌푯값으로 어떤 변화가 있는지 확인함), Pose Estimation

학습 데이터, 검증 데이터, 테스트 데이터(성능을 평가하는 방식)

- Deep Learning에서 가장 중요한 것은 데이터, 데이터가 성능을 좌우함.

1. MODEL

데이터 Input → Feature 추출 → 원하는 Output으로 변하는 구조

(CNN, RNN, Transformer)

1. Loss Function

모델이 예측을 한 값과 실제 값 사이의 차이를 나타냄. 때로는 Loss 함수가 그대로 평가 Metric으로 사용함.

- 회귀 문제에서의 평균 제곱 오차 (MSE)
- 분류 문제에서의 cross-entopy loss와 accuracy metric (클래스 분류를 했을 때, 확률을 통해 Loss를 알아냄)

> 비지도 학습에서는 loss function이 없음. 라벨이 없기에 비교 대상이 존재하지 않기 때문.

### 분류 문제 → 퍼셉트론

---

<aside>
💡

강아지와 고양이를 분류하는 문제

---

강아지/고양이 사진에서 Feature를 뽑아내야 함. (강아지 귀가 얼마나 둥근지, 꼬리는 어떤지)

- 두 그룹을 가장 잘 나누는 직선을 찾음. → 임의로 선을 긋고, Loss 값을 이용하여 가장 좋은 선을 찾아냄.
- Decision Boundary: 가중치 w와 편향 b로 구분하여 무작위 값을 넣고 학습함.
</aside>

이진 분류 모델을 학습하기 위한 지도학습 기반의 알고리즘. → 오류를 최소화하는 방향으로 수정함.

- 단층 퍼셉트론 한계: 선을 그어 구분한다면 XOR 문제 해결 불가능함.
  - → 다층 퍼셉트론으로 해결 (입력/출력 외에 한 층이 더 존재함.)

### 인공 신경망(ANN)

입력데이터/출럭데이터와 관계를 학습하고, 모델링하는 알고리즘

- 뇌의 뉴런들이 서로 연결돼요!

1. 역전파/순전파
2. 역전파: 출력층에서 발생한 오차를 역으로 전파하여 각 뉴런의 가중치로 적용함. [4주차에 계산 그래프로 다룰 예정]
